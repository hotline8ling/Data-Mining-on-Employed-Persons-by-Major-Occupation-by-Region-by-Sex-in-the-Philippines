{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset Shape: (2040, 6)\n",
      "\n",
      "First 5 rows:\n",
      "  Geolocation                  Major Occupation  Year Quarter  Female     Male\n",
      "0       BARMM          Armed Forces Occupations  2019      Q1   0.000    4.913\n",
      "1       BARMM          Clerical Support Workers  2019      Q1   3.094    3.469\n",
      "2       BARMM  Craft and Related Trades Workers  2019      Q1   5.036   36.280\n",
      "3       BARMM            Elementary Occupations  2019      Q1  61.566  181.032\n",
      "4       BARMM                          Managers  2019      Q1  75.293   99.566\n",
      "\n",
      "--- Data Preprocessing ---\n"
     ]
    },
    {
     "ename": "DateParseError",
     "evalue": "Unknown datetime string format, unable to parse: 2019QQ1, at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDateParseError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m     date_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuarter\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# Create a date column from Year and Quarter\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQ\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQuarter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     date_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m# Try to find a date-like column\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rojgi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1063\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1061\u001b[0m             result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[1;32m-> 1063\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_listlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n",
      "File \u001b[1;32mc:\\Users\\rojgi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:247\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[1;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[0;32m    245\u001b[0m unique_dates \u001b[38;5;241m=\u001b[39m unique(arg)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[1;32m--> 247\u001b[0m     cache_dates \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;66;03m# GH#45319\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\rojgi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:435\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[1;32m--> 435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mobjects_to_datetime64\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[0;32m    447\u001b[0m     out_unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\rojgi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2398\u001b[0m, in \u001b[0;36mobjects_to_datetime64\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, allow_object, out_unit)\u001b[0m\n\u001b[0;32m   2395\u001b[0m \u001b[38;5;66;03m# if str-dtype, convert\u001b[39;00m\n\u001b[0;32m   2396\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mobject_)\n\u001b[1;32m-> 2398\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mtslib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2400\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2403\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreso\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mabbrev_to_npy_unit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_unit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2405\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2408\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m   2409\u001b[0m     \u001b[38;5;66;03m#  is in UTC\u001b[39;00m\n\u001b[0;32m   2410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result, tz_parsed\n",
      "File \u001b[1;32mtslib.pyx:414\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtslib.pyx:596\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtslib.pyx:553\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mconversion.pyx:641\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.convert_str_to_tsobject\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsing.pyx:336\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsing.pyx:666\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDateParseError\u001b[0m: Unknown datetime string format, unable to parse: 2019QQ1, at position 0"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading dataset...\")\n",
    "file_path = 'data/Final_Test_Cleaned_DF.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Data Preprocessing\n",
    "print(\"\\n--- Data Preprocessing ---\")\n",
    "data = df.copy()\n",
    "\n",
    "# Create target variable: MALE-DOMINATED or FEMALE-DOMINATED\n",
    "# Checking for Male and Female columns with various naming patterns\n",
    "male_cols = [col for col in data.columns if 'male' in col.lower()]\n",
    "female_cols = [col for col in data.columns if 'female' in col.lower()]\n",
    "\n",
    "if 'Male' in data.columns and 'Female' in data.columns:\n",
    "    data['Gender_Dominance'] = np.where(data['Male'] > data['Female'], 'MALE-DOMINATED', 'FEMALE-DOMINATED')\n",
    "elif male_cols and female_cols:\n",
    "    print(f\"Found male column: {male_cols[0]} and female column: {female_cols[0]}\")\n",
    "    data['Gender_Dominance'] = np.where(data[male_cols[0]] > data[female_cols[0]], 'MALE-DOMINATED', 'FEMALE-DOMINATED')\n",
    "else:\n",
    "    print(\"Could not identify gender columns automatically. Please check column names:\")\n",
    "    print(data.columns.tolist())\n",
    "\n",
    "# Ensure we have a date column for time series analysis\n",
    "if 'Date' in data.columns:\n",
    "    date_col = 'Date'\n",
    "elif 'Year' in data.columns and 'Quarter' in data.columns:\n",
    "    # Create a date column from Year and Quarter\n",
    "    data['Date'] = pd.to_datetime(data['Year'].astype(str) + 'Q' + data['Quarter'].astype(str))\n",
    "    date_col = 'Date'\n",
    "else:\n",
    "    # Try to find a date-like column\n",
    "    date_cols = [col for col in data.columns if 'date' in col.lower() or 'time' in col.lower() or 'year' in col.lower()]\n",
    "    if date_cols:\n",
    "        date_col = date_cols[0]\n",
    "        print(f\"Using {date_col} as date column\")\n",
    "    else:\n",
    "        print(\"No date column found. Creating a dummy date index.\")\n",
    "        data['Date'] = pd.date_range(start='2000-01-01', periods=len(data), freq='Q')\n",
    "        date_col = 'Date'\n",
    "\n",
    "# Ensure date column is datetime type\n",
    "data[date_col] = pd.to_datetime(data[date_col])\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "data['Gender_Dominance_Encoded'] = le.fit_transform(data['Gender_Dominance'])\n",
    "\n",
    "# Prepare time series data\n",
    "# Group by date and calculate the proportion of male-dominated occupations\n",
    "ts_data = data.groupby(date_col).agg(\n",
    "    Male_Dominated_Count=('Gender_Dominance', lambda x: (x == 'MALE-DOMINATED').sum()),\n",
    "    Total_Count=('Gender_Dominance', 'count')\n",
    ").reset_index()\n",
    "\n",
    "ts_data['Male_Dominated_Proportion'] = ts_data['Male_Dominated_Count'] / ts_data['Total_Count']\n",
    "ts_data['Female_Dominated_Proportion'] = 1 - ts_data['Male_Dominated_Proportion']\n",
    "\n",
    "# Set the date as index for time series analysis\n",
    "ts_data.set_index(date_col, inplace=True)\n",
    "ts_data.sort_index(inplace=True)\n",
    "\n",
    "# Plot the time series\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(ts_data.index, ts_data['Male_Dominated_Proportion'], label='Male Dominated')\n",
    "plt.plot(ts_data.index, ts_data['Female_Dominated_Proportion'], label='Female Dominated')\n",
    "plt.title('Gender Dominance Proportion Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Proportion')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Define Optuna objective for SARIMAX parameter optimization\n",
    "def objective(trial):\n",
    "    # Define the parameter space\n",
    "    p = trial.suggest_int('p', 0, 5)\n",
    "    d = trial.suggest_int('d', 0, 2)\n",
    "    q = trial.suggest_int('q', 0, 5)\n",
    "    P = trial.suggest_int('P', 0, 2)\n",
    "    D = trial.suggest_int('D', 0, 1)\n",
    "    Q = trial.suggest_int('Q', 0, 2)\n",
    "    s = 4  # Quarterly data, so seasonality is 4\n",
    "    \n",
    "    # Try to fit the SARIMAX model\n",
    "    try:\n",
    "        model = SARIMAX(\n",
    "            ts_data['Male_Dominated_Proportion'],\n",
    "            order=(p, d, q),\n",
    "            seasonal_order=(P, D, Q, s),\n",
    "            enforce_stationarity=False,\n",
    "            enforce_invertibility=False\n",
    "        )\n",
    "        results = model.fit(disp=False)\n",
    "        \n",
    "        # Return AIC as the objective to minimize\n",
    "        return results.aic\n",
    "    except:\n",
    "        # Return a large value if model fitting fails\n",
    "        return float('inf')\n",
    "\n",
    "# Create and run the Optuna study\n",
    "print(\"Optimizing SARIMAX parameters with Optuna...\")\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "print(\"Best SARIMAX Parameters:\", best_params)\n",
    "\n",
    "# Fit the SARIMAX model with the best parameters\n",
    "p, d, q = best_params['p'], best_params['d'], best_params['q']\n",
    "P, D, Q = best_params['P'], best_params['D'], best_params['Q']\n",
    "s = 4  # Quarterly data\n",
    "\n",
    "print(f\"Fitting SARIMAX model with order=({p},{d},{q}) and seasonal_order=({P},{D},{Q},{s})\")\n",
    "final_model = SARIMAX(\n",
    "    ts_data['Male_Dominated_Proportion'],\n",
    "    order=(p, d, q),\n",
    "    seasonal_order=(P, D, Q, s),\n",
    "    enforce_stationarity=False,\n",
    "    enforce_invertibility=False\n",
    ")\n",
    "final_results = final_model.fit(disp=False)\n",
    "print(final_results.summary())\n",
    "\n",
    "# Forecast for the next 10 years (40 quarters)\n",
    "forecast_steps = 40\n",
    "forecast = final_results.get_forecast(steps=forecast_steps)\n",
    "forecast_mean = forecast.predicted_mean\n",
    "forecast_ci = forecast.conf_int()\n",
    "\n",
    "# Create a date range for the forecast period\n",
    "last_date = ts_data.index[-1]\n",
    "forecast_dates = pd.date_range(start=last_date + pd.DateOffset(months=3), periods=forecast_steps, freq='Q')\n",
    "\n",
    "# Plot the historical data and forecast\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(ts_data.index, ts_data['Male_Dominated_Proportion'], label='Historical Male Dominance')\n",
    "plt.plot(forecast_dates, forecast_mean, label='Forecasted Male Dominance', color='red')\n",
    "plt.fill_between(\n",
    "    forecast_dates,\n",
    "    forecast_ci.iloc[:, 0],\n",
    "    forecast_ci.iloc[:, 1],\n",
    "    color='pink',\n",
    "    alpha=0.3\n",
    ")\n",
    "plt.plot(ts_data.index, ts_data['Female_Dominated_Proportion'], label='Historical Female Dominance', color='green')\n",
    "plt.plot(forecast_dates, 1 - forecast_mean, label='Forecasted Female Dominance', color='orange')\n",
    "plt.title('Gender Dominance Forecast for Next 10 Years (Quarterly)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Proportion')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Create a DataFrame with the forecast results\n",
    "forecast_df = pd.DataFrame({\n",
    "    'Date': forecast_dates,\n",
    "    'Forecasted_Male_Dominance': forecast_mean.values,\n",
    "    'Forecasted_Female_Dominance': 1 - forecast_mean.values,\n",
    "    'Lower_CI_Male': forecast_ci.iloc[:, 0].values,\n",
    "    'Upper_CI_Male': forecast_ci.iloc[:, 1].values\n",
    "})\n",
    "\n",
    "print(\"\\nForecast for the next 10 years (quarterly):\")\n",
    "print(forecast_df.head(10))  # Show first 10 quarters of forecast\n",
    "\n",
    "# Save the forecast to a CSV file\n",
    "forecast_df.to_csv('gender_dominance_forecast.csv', index=False)\n",
    "print(\"Forecast saved to 'gender_dominance_forecast.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting pmdarima\n",
      "  Downloading pmdarima-2.0.4-cp310-cp310-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\rojgi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pmdarima) (1.4.2)\n",
      "Collecting Cython!=0.29.18,!=0.29.31,>=0.29 (from pmdarima)\n",
      "  Downloading Cython-3.0.12-cp310-cp310-win_amd64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\rojgi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pmdarima) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.19 in c:\\users\\rojgi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pmdarima) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\rojgi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pmdarima) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\rojgi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pmdarima) (1.13.1)\n",
      "Requirement already satisfied: statsmodels>=0.13.2 in c:\\users\\rojgi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pmdarima) (0.14.4)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\rojgi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pmdarima) (2.3.0)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in c:\\users\\rojgi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pmdarima) (75.6.0)\n",
      "Requirement already satisfied: packaging>=17.1 in c:\\users\\rojgi\\appdata\\roaming\\python\\python310\\site-packages (from pmdarima) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rojgi\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=0.19->pmdarima) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rojgi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.19->pmdarima) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rojgi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.19->pmdarima) (2024.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\rojgi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=0.22->pmdarima) (3.5.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\rojgi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsmodels>=0.13.2->pmdarima) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rojgi\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas>=0.19->pmdarima) (1.17.0)\n",
      "Downloading pmdarima-2.0.4-cp310-cp310-win_amd64.whl (613 kB)\n",
      "   ---------------------------------------- 0.0/613.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 613.3/613.3 kB 23.4 MB/s eta 0:00:00\n",
      "Downloading Cython-3.0.12-cp310-cp310-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.8/2.8 MB 81.2 MB/s eta 0:00:00\n",
      "Installing collected packages: Cython, pmdarima\n",
      "Successfully installed Cython-3.0.12 pmdarima-2.0.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
